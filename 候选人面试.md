



### 面试算法题

#### 1. 输入整数数组 `arr` ，找出其中最小的 `k` 个数。例如，输入4、5、1、6、2、7、3、8这8个数字，则最小的4个数字是1、2、3、4。

https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/solution/zui-xiao-de-kge-shu-by-leetcode-solution/

```
输入：arr = [3,2,1], k = 2
输出：[1,2] 或者 [2,1]
```

```
输入：arr = [0,1,2,1], k = 1
输出：[0]
```

```
func getLeastNumbers(arr []int, k int) []int {

    if k == 0 {
        return []int{}
    }

    start := 0
    end := len(arr)-1

    index := part(arr, start, end)

    for index != k-1 {
        if index > k-1 {
            end = index-1
        }else if index < k-1 {
            start = index + 1
        }
        index = part(arr, start, end)
    }
    return arr[:k]
}

func part(arr []int, start, end int) int {
    index := start
    pivot := arr[end] 
    for i:= start; i < end; i++ {
        if arr[i] < pivot {
            arr[i], arr[index] = arr[index], arr[i]
            index++
        }
    }
```

```
func getLeastNumbers(arr []int, k int) []int {
    a := IntHeap(arr)
    h := &IntHeap{}
    h = &a
    heap.Init(h)
    var res []int
    for k > 0 {
        res = append(res, heap.Pop(h).(int))
        k--
    }
    return res
}

type IntHeap []int

func (h IntHeap)Len()int{return len(h)}
func (h IntHeap)Swap(i, j int){h[i], h[j]=h[j], h[i]}
func (h IntHeap)Less(i, j int)bool{return h[i] < h[j]}

func (h *IntHeap)Push(x interface{}){
    *h = append(*h, x.(int))
}
func (h *IntHeap) Pop() interface{} {
    old := *h
    n := len(old)
    x := old[n-1]
    *h = old[:n-1]
    return x
}
```

#### 2.输入一棵二叉树的根节点，求该树的深度。从根节点到叶节点依次经过的节点（含根、叶节点）形成树的一条路径，最长路径的长度为树的深度。

例如：

给定二叉树 [3,9,20,null,null,15,7]，

```
    3
   / \
  9  20
    /  \
   15   7
```

返回它的最大深度 3 。

```
func maxDepth(root *TreeNode) int {
    return layer(root)
}

func layer(root *TreeNode) int {
    if root == nil {
         return 0
    }

    layers := 0
    nodes := []*TreeNode{root}
    for len(nodes) > 0 {
        layers++
        size := len(nodes)
        count := 0
        for count < size {
            count++
            curNode := nodes[0]
            nodes = nodes[1:]
            if curNode.Left != nil {
                nodes = append(nodes, curNode.Left)
            }
            if curNode.Right != nil {
                nodes = append(nodes, curNode.Right)
            }
        }
    }
    return layers
}
```

```
func maxDepth(root *TreeNode) int {
    if root == nil {
        return 0
    }
    return max(maxDepth(root.Left), maxDepth(root.Right)) + 1
}

func max(x, y int) int {
    if x > y {
         return x
    }
    return y
}
```

#### 3. 输入一个递增排序的数组和一个数字s，在数组中查找两个数，使得它们的和正好是s。如果有多对数字的和等于s，则输出任意一对即可。

```
输入：nums = [2,7,11,15], target = 9
输出：[2,7] 或者 [7,2]
```

```
输入：nums = [10,26,30,31,47,60], target = 40
输出：[10,30] 或者 [30,10]
```

```
func twoSum(nums []int, target int) []int {
    i := 0
    j := len(nums)-1

    for i < j {
        if nums[i] + nums[j] < target{
            i++
        }else if nums[i]+ nums[j] == target {
            return []int{nums[i], nums[j]}
        }else if nums[i]+nums[j] > target{
            j--
        }
    } 
    return []int{}
}
```



### 2.kubernete问题排查部分

#### 1.Pod一直Terminating状态

有可能三种情况：

- ``` Killing container with id docker://apigateway:Need to kill Pod ```

  这种情况可能是磁盘满了

- ```code = DeadlineExceeded desc = context deadline exceeded```

  这种情况可能是docker17的dockerd的bug 可通过```kubectl delete po name --force --grace-period=0```删除

- 存在finalizers

  通过```kubectl edit```手动编辑资源定义删除finalizers

#### deployment 创建过程

文章：https://juejin.cn/post/6844903971430072328

​			http://dockone.io/article/9134



孤儿进程、僵尸进程、守护进程

孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程，孤儿进程将被init进程（进程号为1）所收养，并由init进程对它们完成状态收集工作。由于孤儿进程会被init进程收养，所以孤儿进程不会对系统造成伤害。

僵尸进程：一个进程fork创建子进程，如果子进程退出，父进程没有调用wait或者waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中，这种进程称为僵尸进程。

守护进程：独立于控制终端并且周期性的执行某种任务或等待处理某些发生的事件。他不需要用户输入就能运行而且提供某种服务，不是对整个系统就是对某个用户程序提供服务。如mysqld、syslogd、httpd。守护进程的父进程是init进程，因为它真正的父进程在fork出子进程就先于子进程exit退出了。

### 9.进程 线程 协程



### C++

什么是多态，C++是如何实现多态的。





### git

```
#初始化本地仓库
git init
#添加全部已经修改的文件，准备commit提交 该命令效果等同于 git add -A
git add .
#将修改后的文件提交本地仓库 
git commit -m "提交说明"
#链接到远程仓库，并将代码同步到远程仓库
git remote add origin 远程仓库地址

#创建一个 upStream （上传流），并将本地代码通过这个 upStream 推送到 别名为 origin 的仓库中的 master 分支
#-u ，就是创建 upStream 上传流，如果没有这个上传流就无法将代码推送到 github；同时，这个 upStream 只需要在初次推送代码的时候创建，以后就不用创建了
#另外，在初次 push 代码的时候，可能会因为网络等原因导致命令行终端上的内容一直没有变化，耐心等待一会就好。
git push -u origin master

#如果有多个远程仓库 或者 多个分支， 并且需要将代码推送到指定仓库的指定分支上，那么在 pull 或者 push 的时候，就需要 按照下面的格式书写：

git pull 仓库别名 仓库分支名 
git push 仓库别名 仓库分支名

#抛弃本地所有的修改，回到远程仓库的状态
git fetch --all && git reset --hard origin/mster

#重设第一个commit
#也就是把所有的改动都重新放回工作区，并清空所有的commit 这样就可以重新提交一次commit了
git update-ref -d HEAD

#还可以展示本地仓库中任意两个 commit 之间的文件变动
git diff <commit -id> <commit -id>

#输出暂存区和本地最近的版本（commit）的 different（不同）
git diff --cached

#输出工作区、暂存区 和本地最近的版本（commit）的 different（不同）
git diff HEAD

#快速切换到上一个分支
git checkout -

#删除已经合并到 master 的分支
git branch --merged master | grep -v '^\*\| master'|xargs -n git branch -d 

#展示本地分支关联远程仓库的情况
git branch -vv

#列出所有远程分支
git branch -r

#列出本地和远程分支
git branch -a

#创建并切换到本地分支
git checkout -b <branch-name>
#从远程分支中创建并切换到本地分支
git checkout -b <branch-name> origin/<branch-name>

#删除本地分支
git  branch -d <local-branchname>

#删除远程分支
git push origin --delete <remote-branchname>
git push origin :<remote-branchname>

#重命名本地分支
git branch -m <new-branch-name>

#查看标签
git tag

#展示当前分支的最近的tag
git describe --tags --abbrev=0

#放弃工作区的修改
git checkout <file-name>

#放弃所有修改
git checkout .

#恢复删除的文件
git rev-list -n 1 HEAD --<file_path>#得到deleting_commit
git checkout <delete_commit>^ -- <file_path> #回到删除文件 deleting_commit 之前的状态


#本地与远程的差集
git log local_branch..origin/remote_branch

#统计文件的改动
git diff --stat local_branch origin/remote_branch

#git 回滚到之前的某一个commit

1. git log 查看要回滚的一个commit
2.git reset --hard <commit hash id>
```



## 问题顺序

### 1. k8s：

1. kubernetes 架构以及各组件的作用 
2. calico ipip模式通信过程 
3. kubernetes-scheduler调度过程 
8. qos三个等级  

```

    kubelet 启动
    kubelet 看到自己 没有 对应的 kubeconfig 文件
    kubelet 搜索并发现 bootstrap-kubeconfig 文件
    kubelet 读取该启动引导文件，从中获得 API 服务器的 URL 和用途有限的 一个“令牌（Token）”
    kubelet 建立与 API 服务器的连接，使用上述令牌执行身份认证
    kubelet 现在拥有受限制的凭据来创建和取回证书签名请求（CSR）
    kubelet 为自己创建一个 CSR，并将其 signerName 设置为 kubernetes.io/kube-apiserver-client-kubelet
    CSR 被以如下两种方式之一批复：
       如果配置了，kube-controller-manager 会自动批复该 CSR
       如果配置了，一个外部进程，或者是人，使用 Kubernetes API 或者使用 kubectl 来批复该 CSR
    kubelet 所需要的证书被创建
    证书被发放给 kubelet
    kubelet 取回该证书
    kubelet 创建一个合适的 kubeconfig，其中包含密钥和已签名的证书
    kubelet 开始正常操作
    可选地，如果配置了，kubelet 在证书接近于过期时自动请求更新证书
    更新的证书被批复并发放；取决于配置，这一过程可能是自动的或者手动完成
```



1. deploy创建过程
2. Informer 机制

### docker

#### 1. docker存储一个镜像的命令是什么

#### 2、如何批量清理临时镜像文件？ ... 

#### 2、如何查看镜像支持的环境变量？ ... 

#### 3、本地的镜像文件都存放在哪里 ... 

#### 4、构建**Docker**镜像应该遵循哪些原则？ ... 

#### 1、容器退出后，通过**docker** ps 命令查看不到，数据会丢失么？ ... 

#### 2、如何停止所有正在运行的容器？

### 2. git：

```
#git 回滚到之前的某一个commit

1. git log 查看要回滚的一个commit
2.git reset --hard <commit hash id>


#删除本地分支
git  branch -d <local-branchname>

#放弃所有修改
git checkout .

#重命名本地分支
git branch -m <new-branch-name>

#还可以展示本地仓库中任意两个 commit 之间的文件变动
git diff <commit -id> <commit -id>
```

### 3. linux:

#### 1. cgroup有哪些子系统

1. cpu 子系统，主要限制进程的 cpu 使用率。
2. cpuacct 子系统，可以统计 cgroups 中的进程的 cpu 使用报告。
3. cpuset 子系统，可以为 cgroups 中的进程分配单独的 cpu 节点或者内存节点。
4. memory 子系统，可以限制进程的 memory 使用量。
5. blkio 子系统，可以限制进程的块设备 io。
6. devices 子系统，可以控制进程能够访问某些设备。
7. net_cls 子系统，可以标记 cgroups 中进程的网络数据包，然后可以使用 tc 模块（traffic control）对数据包进行控制。
8. freezer 子系统，可以挂起或者恢复 cgroups 中的进程。
9. ns 子系统，可以使不同 cgroups 下面的进程使用不同的 namespace。

#### 2. namespace：**namespace 是 Linux 内核用来隔离内核资源的方式**

| **Mount namespaces**   | CLONE_NEWNS   | [Linux 2.4.19](https://lwn.net/2001/0301/a/namespaces.php3)  |
| ---------------------- | ------------- | ------------------------------------------------------------ |
| **UTS namespaces**     | CLONE_NEWUTS  | [Linux 2.6.19](https://lwn.net/Articles/179345/)             |
| **IPC namespaces**     | CLONE_NEWIPC  | [Linux 2.6.19](https://lwn.net/Articles/187274/)             |
| **PID namespaces**     | CLONE_NEWPID  | [Linux 2.6.24](https://lwn.net/Articles/259217/)             |
| **Network namespaces** | CLONE_NEWNET  | [始于Linux 2.6.24 完成于 Linux 2.6.29](https://lwn.net/Articles/219794/) |
| **User namespaces**    | CLONE_NEWUSER | [始于 Linux 2.6.23 完成于 Linux 3.8)](https://lwn.net/Articles/528078/) |

#### 2. df 和du 的工作原理

##### 2.1 du的工作原理

du命令会对待统计文件逐个调用fstat这个系统调用，获取文件大小。它的数据是基于文件获取的，所以有很大的灵活性，不一定非要针对一个分区，可以跨越多个分区操作。如果针对的目录中文件很多，du速度就会很慢了。

##### 2.2 df的工作原理

df命令使用的事statfs这个系统调用，直接读取分区的超级块信息获取分区使用情况。它的数据是基于分区元数据的，所以只能针对整个分区。由于df直接读取超级块，所以运行速度不受文件多少影响。

```
df -h
du -sh
```

##### 问题原因

du命令对统计的文件逐个进行fstat系统调用，获取文件大小。它的数据是基于文件获取，可以跨多个分区操作。df命令使用statfs系统调用，直接读取分区的超级块信息获取分区使用情况。它的数据基于分区元数据，只能针对整个分区。

删除大量的文件后，du命令不会在文件系统目录中统计删除的文件。如果此时还有运行中的进程持有被删除文件的句柄，那么此文件就不会真正的在磁盘中被删除，分区超级块中的信息也就不会更改，df命令仍会统计被删除文件的信息。



#### 4.输入url发生了什么

1. dns解析
2. 建立tcp连接
3. 发送http请求
4. 关闭tcp连接
5. 浏览器渲染

参考文章：https://mp.weixin.qq.com/s/DLq_GIkdnuOayThfi3jI0A

#### 5.http的请求方式（get post区别）

==**get**==： 主要获取信息方法，大量的性能优化都是针对该方法，幂等方法

==**HEAD**==：类似get方法，但服务器不发送body，用以获取HEAD元数据，幂等方法

==**POST**==：常用于提交form表单，新增资源

==**PUT**==：更新资源

==**DELETE**==：删除资源，幂等方法

==**TRACE**==：回显服务器收到的请求，用于定位问题。有安全风险

==**OPTIONS**==： 显示服务器对访问资源支持的方法，幂等方法

==**CONNECT**==： 建立tunnel隧道



#### 5.5 HTTP 和 HTTPS 的区别

##### –  三次握手四次挥手https://hit-alibaba.github.io/interview/basic/network/TCP.html

##### 5.6 并行和并发

- 并发:一个处理器同时处理多个任务。
- 并行:多个处理器或者是多核的处理器同时处理多个不同的任务.

##### - HTTPS 是如何实现安全数据传输的？

#### 8. 进程与线程区别

**进程**：进程是系统资源分配的最小单位，系统有一个个进程（程序）组成 包括文本区域、数据区域、堆栈区域

- 文本区域存储处理器执行的代码
- 数据区域存储变量和进程执行期间使用的动态分配的内存
- 堆栈区域存储着活动过程调用的指令和本地变量

因此进程的创建和销毁都是相对于系统资源。进程有三个状态：

- 等待态：等待某个事件完成
- 就绪态：等待系统分配处理器以便运行
- 运行态：占有处理器正在运行

通信问题：由于进程间是隔离的，各自拥有自己的内存资源，因此相对于线程是安全的，所以不同进程间通信只能通过IPC（inter process communication）进行通信共享

**线程**：

1. 线程属于进程
2. 线程共享进程的内存地址空间
3. 线程在进程内部可以通过全局变量进行通信 由此可以带来多个线程读写一个地址的情况 将带来不可预期的后果 因此引入了锁机制 例如互斥锁

- 线程是cpu调度的最小单位
- 进程是系统分配资源的最小单位

==线程和进程的上下文切换==

进程切换分为三步

1. 切换页目录 以使用新的地址空间
2. 切换内核栈
3. 切换硬件上下文

==线程切换需要2.3步==

**协程**：协程是属于线程的 协程程序是在线程里面跑的，因此协程又称微线程和纤程

协程没有线程的上下文切换 协程的调度是由程序员手动切换的 因此又叫做用户空间线程

由于协程是用户调度的 所以不会出现执行一半的代码片段被强制中断 因此无需原子操作锁

##### 解释一下孤儿进程、僵尸进程、守护进程

孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程，孤儿进程将被init进程（进程号为1）所收养，并由init进程对它们完成状态收集工作。由于孤儿进程会被init进程收养，所以孤儿进程不会对系统造成伤害。

僵尸进程：一个进程fork创建子进程，如果子进程退出，父进程没有调用wait或者waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中，这种进程称为僵尸进程。

守护进程：独立于控制终端并且周期性的执行某种任务或等待处理某些发生的事件。他不需要用户输入就能运行而且提供某种服务，不是对整个系统就是对某个用户程序提供服务。如mysqld、syslogd、httpd。守护进程的父进程是init进程，因为它真正的父进程在fork出子进程就先于子进程exit退出了。

#### 401状态码

请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。

#### 403

服务器已经理解请求，但是拒绝执行它。与401响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交。



#### tcp和udp区别 udp  udp适用场景

#### 说一下linux中的文件描述符

文件描述符：File descriptor,简称fd，当应用程序请求内核打开/新建一个文件时，内核会返回一个文件描述符用于对应这个打开/新建的文件，其fd本质上就是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。

inode和文件描述符有什么联系吗 ？

硬连接和软连接区别是什么？

#### 怎样查看系统负载

top uptime等

#### 文件删除，但是空间未释放什么原因

通常不会出现删除文件后空间不释放的情况，特殊情况是文件进程锁定，或有进程一直在向这个文件写数据



#### 软连接和硬连接



### 4. mysql

#### 2. MySQL 常见存储引擎

##### InnoDB 

- 支持事务操作，具有事务 ACID 隔离特性，默认的隔离级别是`可重复读(repetable-read)`、通过MVCC（并发版本控制）来实现的。能够解决`脏读`和`不可重复读`的问题。
- InnoDB 支持外键操作。
- InnoDB 默认的锁粒度`行级锁`，并发性能比较好，会发生死锁的情况。
- 和 MyISAM 一样的是，InnoDB 存储引擎也有 `.frm文件存储表结构` 定义，但是不同的是，InnoDB 的表数据与索引数据是存储在一起的，都位于 B+ 数的叶子节点上，而 MyISAM 的表数据和索引数据是分开的。
- InnoDB 有安全的日志文件，这个日志文件用于恢复因数据库崩溃或其他情况导致的数据丢失问题，保证数据的一致性。
- InnoDB 和 MyISAM 支持的索引类型相同，但具体实现因为文件结构的不同有很大差异。
- 增删改查性能方面，果执行大量的增删改操作，推荐使用 InnoDB 存储引擎，它在删除操作时是对行删除，不会重建表。

##### MyISAM 和 InnoDB 存储引擎的对比

- `锁粒度方面`：由于锁粒度不同，InnoDB 比 MyISAM 支持更高的并发；InnoDB 的锁粒度为行锁、MyISAM 的锁粒度为表锁、行锁需要对每一行进行加锁，所以锁的开销更大，但是能解决脏读和不可重复读的问题，相对来说也更容易发生死锁
- `可恢复性上`：由于 InnoDB 是有事务日志的，所以在产生由于数据库崩溃等条件后，可以根据日志文件进行恢复。而 MyISAM 则没有事务日志。
- `查询性能上`：MyISAM 要优于 InnoDB，因为 InnoDB 在查询过程中，是需要维护数据缓存，而且查询过程是先定位到行所在的数据块，然后在从数据块中定位到要查找的行；而 MyISAM 可以直接定位到数据所在的内存地址，可以直接找到数据。
- `表结构文件上`： MyISAM 的表结构文件包括：.frm(表结构定义),.MYI(索引),.MYD(数据)；而 InnoDB 的表数据文件为:.ibd和.frm(表结构定义)；

##### 3. 什么是临时表，何时删除临时表

什么是临时表？MySQL 在执行 SQL 语句的过程中，通常会临时创建一些`存储中间结果集`的表，临时表只对当前连接可见，在连接关闭时，临时表会被删除并释放所有表空间。

临时表分为两种：一种是`内存临时表`，一种是`磁盘临时表`，什么区别呢？内存临时表使用的是 MEMORY 存储引擎，而临时表采用的是 MyISAM 存储引擎。

> MEMORY 存储引擎：`memory` 是 MySQL 中一类特殊的存储引擎，它使用存储在内容中的内容来创建表，而且**数据全部放在内存中**。每个基于 MEMORY 存储引擎的表实际对应一个磁盘文件。该文件的文件名与表名相同，类型为 `frm` 类型。而其数据文件，都是存储在内存中，这样有利于数据的快速处理，提高整个表的效率。MEMORY  用到的很少，因为它是把数据存到内存中，如果内存出现异常就会影响数据。如果重启或者关机，所有数据都会消失。因此，基于 MEMORY  的表的生命周期很短，一般是一次性的。

MySQL 会在下面这几种情况产生临时表

- 使用 UNION 查询：UNION 有两种，一种是` UNION` ，一种是 `UNION ALL` ，它们都用于联合查询；区别是 使用 UNION 会去掉两个表中的重复数据，相当于对结果集做了一下`去重(distinct)`。使用 UNION ALL，则不会排重，返回所有的行。使用 UNION 查询会产生临时表。
- 使用 `TEMPTABLE 算法`或者是 UNION 查询中的视图。TEMPTABLE 算法是一种创建临时表的算法，它是将结果放置到临时表中，意味这要 MySQL 要先创建好一个临时表，然后将结果放到临时表中去，然后再使用这个临时表进行相应的查询。
- ORDER BY 和 GROUP BY 的子句不一样时也会产生临时表。
- DISTINCT 查询并且加上 ORDER BY 时；
- SQL中用到 SQL_SMALL_RESULT 选项时；如果查询结果比较小的时候，可以加上 SQL_SMALL_RESULT 来优化，产生临时表
- FROM 中的子查询；
- EXPLAIN 查看执行计划结果的 Extra 列中，如果使用 `Using Temporary` 就表示会用到临时表

##### 4. MySQL 常见索引类型

索引是存储在一张表中特定列上的`数据结构`，索引是在列上创建的。并且，索引是一种数据结构。

在 MySQL 中，主要有下面这几种索引

- `全局索引(FULLTEXT)`：全局索引，目前只有 MyISAM 引擎支持全局索引，它的出现是为了解决针对文本的模糊查询效率较低的问题。
- `哈希索引(HASH)`：哈希索引是 MySQL 中用到的唯一 key-value 键值对的数据结构，很适合作为索引。HASH 索引具有一次定位的好处，不需要像树那样逐个节点查找，但是这种查找适合应用于查找单个键的情况，对于范围查找，HASH 索引的性能就会很低。
- `B-Tree 索引`：B 就是 Balance 的意思，BTree 是一种平衡树，它有很多变种，最常见的就是 B+ Tree，它被 MySQL 广泛使用。
- `R-Tree 索引`：R-Tree 在 MySQL 很少使用，仅支持 geometry 数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种，相对于 B-Tree 来说，R-Tree 的优势在于范围查找。

##### 简述Redis有哪几种持久化策略 及比较？

RDB：每隔一段时间对Redis进行一次持久化
   -   缺点：数据不完整
   -   优点：速度快

AOF：把所有命令保存起来，如果想到重新生成到Redis，那么就要把命令重新执行一次
   - 缺点：速度慢，文件比较大
   - 优点：数据完整

### 5. python

#### 1. Python 的 yield 关键字有什么作用？

- 保存当前运行状态，然后暂停执行，即将函数挂起。yield关键字后面表达式的值作为返回值返回。当使用next()、send()函数从断点处继续执行

#### 2.**Python的列表和元组有什么区别？**

- 可变与不可变（列表是可变的而元组是不可变的）
- 速度（元组比列表更快）

#### 3. **Python中的深拷贝和浅拷贝有什么区别？**

- copy.copy（浅拷贝） 只拷贝父对象，不会拷贝对象的内部的子对象

- copy.deepcopy（ 深拷贝） 拷贝对象及其子对象

#### 4. **生成器、迭代器的区别**

- 生成器能做到迭代器能做的所有事,而且因为自动创建了 iter()和  next()方法,生成器显得特别简洁,而且生成器也是高效的，使用生成器表达式取代列表解析可以同时节省内存。除了创建和保存程序状态的自动方法,当发生器终结时,还会自动抛出 StopIteration 异常

#### 5.**函数装饰器有什么作用**

- 装饰器本质上是一个Python函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景。有了装饰器，就可以抽离出大量与函数功能本身无关的雷同代码并继续重用





### 6. golang

- new和make的区别

**答：** 1. 两者都用于在堆上分配内存

​		2. new是初始化一个类型 并返回内存地址， 即返回一个类型为T 值为0的地址指针

	    3. make只适用于三种内建的引用类型：slice、channel、map 并返回初始值

- go中select的作用

**答**：select是监听和channel有关的IO操作，当IO操作发生时，触发相应的动作

```
//基本用法
select {
    case <- chan1:
    //如果chan1成功读到数据， 则进行该case处理语句
    case chan2 <- 1:
    //如果成功向chan2写入数据，则进行该case处理语句
    default:
    //如果上面都没有成功，则进入default处理流程
}
```

- 触发 GC 的时机是什么

主要有两种形式

1. **主动触发**：通过调用runtime.GC来触发GC，此调用阻塞式等待当前GC运行完毕
2. **被动触发**：分为两种
   1. 使用系统监控：当超过两分钟没有产生任何GC 则强制触发GC
   2. 使用步调（pacing）算法，其核心思想是控制内存增长的比例

- 两个协程交替打印1-100奇数偶数

```golang
func go1(p chan int){
	for i := 1; i < 101; i++ {
		p <- i
		if i % 2 == 1 {
			fmt.Println("go1  : ", i)
		}
	}
}
func go2(p chan int) {
	for i := 1; i < 101;  i++{
		<- p
		if i % 2 == 0{
			fmt.Println("go2  : ", i)
		}
	}
}
func main() {
	msg := make(chan int)
	go go1(msg)
	go go2(msg)
	time.Sleep(time.Second*1)
}
```

-  go中调度器模型
  - P的数量
    - 由启动时环境变量 GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 GOMAXPROCS 个 goroutine 在同时运行。
  - M的数量：
    - go 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。
- **复用线程**：避免频繁的创建、销毁线程，而是对线程的复用。
  - work stealing 机制：        当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。
  - hand off 机制：        当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行

go逃逸分析是怎么回事 内存什么时候栈分配 什么是堆分配

- beego有几种路由方式
  - 固定路由
  - 正则路由
  - 自定义方法及restful规则
  - 自动匹配
  - 注解路由
  - 方法表达式路由

限流器有哪几种 能不能实现一下 





### 7. 算法题

#### 1. 实现一下快速排序

时间复杂度：Θ(𝑛log𝑛).     最坏情况是𝑛2     快排的空间复杂度是Θ(lg𝑛)

```python
def quick_sort(lists,i,j):
    if i >= j:
        return list
    pivot = lists[i]
    low = i
    high = j
    while i < j:
        while i < j and lists[j] >= pivot:
            j -= 1
        lists[i]=lists[j]
        while i < j and lists[i] <=pivot:
            i += 1
        lists[j]=lists[i]
    lists[j] = pivot
    quick_sort(lists,low,i-1)
    quick_sort(lists,i+1,high)
    return lists
```



#### 2. 两个队列实现栈

```python
class CQueue:

    def __init__(self):
        self.stack1, self.stack2 = [], []

    def appendTail(self, value: int) -> None:
        self.stack1.append(value)

    def deleteHead(self) -> int:
        if self.stack2:
            return self.stack2.pop()
        while self.stack1:
            self.stack2.append(self.stack1.pop())
        if not self.stack2:
            return -1
        else:
            return self.stack2.pop()

```

```python
class CQueue:

    def __init__(self):
        self.stack1 = []
        self.stack2 = []

    def appendTail(self, value: int) -> None:
        # 1 -> 2
        while self.stack1:
            self.stack2.append(self.stack1.pop())
        # add value
        self.stack1.append(value)
        # 1 <- 2
        while self.stack2:
            self.stack1.append(self.stack2.pop())
        return self.stack1

    def deleteHead(self) -> int:
        if not self.stack1: return -1
        return self.stack1.pop()


```

复杂度分析

1. 插入

    时间复杂度：O(n)。
    空间复杂度：O(n)，使用了辅助栈的空间。

2. 删除

    时间复杂度：O(n)。
    空间复杂度：O(n)，stack1 当作了队列，直接在原队列上删除，没使用额外空间。





















```python
class CQueue(object):

    def __init__(self):


    def appendTail(self, value):
        """
        :type value: int
        :rtype: None
        """


    def deleteHead(self):
        """
        :rtype: int
        """

```







```go
type CQueue struct {
    l1 *list.List
    l2 *list.List
}


func Constructor() CQueue {
    return CQueue{
        l1: list.New(),
        l2: list.New()}
}


func (this *CQueue) AppendTail(value int)  {
    this.l1.PushBack(value)
}


func (this *CQueue) DeleteHead() int {
    if this.l2.Len() == 0 {
        for this.l1.Len() != 0 {
            this.l2.PushBack(this.l1.Remove(this.l1.Back()))
        }
    }
    if this.l2.Len() != 0 {
        e := this.l2.Back()
        this.l2.Remove(e)
        return e.Value.(int)
    }
    return -1
}
```



### 其他题

- 做项目过程中最大的挑战是什么
- 最近学习什么技术
